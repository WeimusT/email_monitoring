{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "import dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Literal\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from email_assistant.utils import parse_email, format_email_markdown\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, default_triage_instructions, default_background\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import END\n",
    "from langgraph.types import Command\n",
    "\n",
    "from langgraph.graph import MessagesState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email\"\"\"\n",
    "    # TODO: Implement email sending logic here\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}.\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # TODO: Implement meeting scheduling logic here\n",
    "    date_str = preferred_day.strftime(\"%A, %B %d, %Y\")\n",
    "    return f\"Meeting '{subject}' scheduled on {date_str} at {start_time} for {duration_minutes} minutes with attendees: {', '.join(attendees)}.\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # TODO: Implement calendar availability checking logic here\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM.\"\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "    \"\"\"E-mail has been sent.\"\"\"\n",
    "    done: bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Router\n",
    "\n",
    "Router handles the user query triage.\n",
    "\n",
    "It is important to consider the information to track over the agent graph. This information is the **State**. We use langchain prebuilt `MessageState`, which is a dictionary with a `messages` key that appends messages returned by nodes as its update logic. We extend the `MessageState` object and adds custom keys to suit this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    email_input: dict\n",
    "    classification_decision: Literal['ignore', 'respond', 'notify']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f97eff32c5', 'id': 'chatcmpl-D4DpVkBASAzvPUzqMJ45tsoyF7Oyg', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='lc_run--019c1631-231c-7290-b2df-befa7539155b-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "model_name = os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]\n",
    "\n",
    "azure_model = init_chat_model(\n",
    "    model=f\"azure_openai:{model_name}\",                  # target model family\n",
    "    model_provider=\"azure_openai\",               # tell LC to use Azure OpenAI\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=model_name,  # deployment name in Azure\n",
    "    temperature=0.5,\n",
    "    timeout=10,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# Test the model connection\n",
    "response = azure_model.invoke([\n",
    "    (\"human\", \"Hello, Azure OpenAI\")\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router LLM\n",
    "\n",
    "Define the structured output of the router LLM, and assign the schema to the router LLM using `with_structured_output` function. The LLM output will be coerced to follow the output schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterSchema(BaseModel):\n",
    "    \"\"\"Anallyze the unread email and route it according to its content.\"\"\"\n",
    "    reasoning: str = Field(\n",
    "        description=\"Step-by-step reasoning behind the classification\"\n",
    "    )\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description=\"\"\"\n",
    "The classification of an email: ''\n",
    "- 'ignore' for irrelevant emails.\n",
    "- 'notify' for important information that doesn't need a response.\n",
    "- 'respond' for emails that need a reply.\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a structured output LLM with the defined schema\n",
    "router_llm = azure_model.with_structured_output(RouterSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Node\n",
    "\n",
    "The router is a node in the LangGraph agent graph. We define the router as a function that takes the `MessagesState` defined earlier, and returns appropriate node to move onto next. In this work, the router node can optionally move to the `response_agent` node or the `END` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_router(state: State) -> Command[Literal[\"response_agent\", END]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\"\"\"\n",
    "\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=default_triage_instructions\n",
    "    )\n",
    "\n",
    "    # construct the user prompt using the email details\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author,\n",
    "        to=to,\n",
    "        subject=subject,\n",
    "        email_thread=email_thread\n",
    "    )\n",
    "    # invoke the LLM with the system and user prompts\n",
    "    result = router_llm.invoke_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", user_prompt)\n",
    "    ])\n",
    "    # The result is automatically parsed into the RouterSchema\n",
    "    if result.classification == \"respond\":\n",
    "        print(\"Classification: RESPOND - This email requires a response.\")\n",
    "        # Next node to go to\n",
    "        goto = \"response_agent\"\n",
    "        # Update agent state\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\n",
    "                }\n",
    "            ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the triage system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "< Role >\n",
      "Your role is to triage incoming emails based upon instructs and background information below.\n",
      "</ Role >\n",
      "\n",
      "< Background >\n",
      "{background}. \n",
      "</ Background >\n",
      "\n",
      "< Instructions >\n",
      "Categorize each email into one of three categories:\n",
      "1. IGNORE - Emails that are not worth responding to or tracking\n",
      "2. NOTIFY - Important information that worth notification but doesn't require a response\n",
      "3. RESPOND - Emails that need a direct response\n",
      "Classify the below email into one of these categories.\n",
      "</ Instructions >\n",
      "\n",
      "< Rules >\n",
      "{triage_instructions}\n",
      "</ Rules >\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(triage_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the email triage instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emails that are not worth responding to:\n",
      "- Marketing newsletters and promotional emails\n",
      "- Spam or suspicious emails\n",
      "- CC'd on FYI threads with no direct questions\n",
      "\n",
      "There are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\n",
      "- Team member out sick or on vacation\n",
      "- Build system notifications or deployments\n",
      "- Project status updates without action items\n",
      "- Important company announcements\n",
      "- FYI emails that contain relevant information for current projects\n",
      "- HR Department deadline reminders\n",
      "- Subscription status / renewal reminders\n",
      "- GitHub notifications\n",
      "\n",
      "Emails that are worth responding to:\n",
      "- Direct questions from team members requiring expertise\n",
      "- Meeting requests requiring confirmation\n",
      "- Critical bug reports related to team's projects\n",
      "- Requests from management requiring acknowledgment\n",
      "- Client inquiries about project status or features\n",
      "- Technical questions about documentation, code, or APIs (especially questions about missing endpoints or features)\n",
      "- Personal reminders related to family (wife / daughter)\n",
      "- Personal reminder related to self-care (doctor appointments, etc)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(default_triage_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
